{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aungthuhein13/Real-Estate-Price-Predator/blob/main/real_estate_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrapping Data\n",
        "\n"
      ],
      "metadata": {
        "id": "rha7ifaZ6EZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMglFfuFbVN-",
        "outputId": "63a9e4bc-db31-42ae-bd85-b6179d82eac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topgolf | Rating: 3.1 | Reviews: 176\n",
            "Amici's East Coast Pizzeria at Mid Market Eats Food Hall | Rating: 2.9 | Reviews: 28\n",
            "Bottega | Rating: 4.3 | Reviews: 1459\n",
            "Sobakatsu | Rating: 4.5 | Reviews: 167\n",
            "GiGi's | Rating: 4.2 | Reviews: 37\n",
            "Flora King | Rating: 4.7 | Reviews: 15\n",
            "Milos Meze | Rating: 4.8 | Reviews: 165\n",
            "Altamirano Restaurant & Bar | Rating: 4.5 | Reviews: 87\n",
            "Modí | Rating: 4.3 | Reviews: 99\n",
            "Supreme Dumpling Stonestown | Rating: 4.6 | Reviews: 572\n",
            "Fog Harbor Fish House | Rating: 4.4 | Reviews: 11827\n",
            "Sotto Mare | Rating: 4.3 | Reviews: 5704\n",
            "Subway | Rating: 2.2 | Reviews: 56\n"
          ]
        }
      ],
      "source": [
        "# # Testing from Yelp\n",
        "\n",
        "# import requests\n",
        "# import json\n",
        "\n",
        "# url = \"https://www.yelp.com/gql/batch\"\n",
        "\n",
        "# headers = {\n",
        "#     \"accept\": \"*/*\",\n",
        "#     \"content-type\": \"application/json\",\n",
        "#     \"origin\": \"https://www.yelp.com\",\n",
        "#     \"referer\": \"https://www.yelp.com/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA\",\n",
        "#     \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36 Edg/137.0.0.0\",\n",
        "#     \"x-apollo-operation-name\": \"GetBizData,GetConsumerFooterCopyrightData,GetCCPAStatusForUser\"\n",
        "# }\n",
        "\n",
        "# cookies = {\n",
        "#     # Trimmed down version – include only essential cookies\n",
        "#     \"hl\": \"en_US\",\n",
        "#     \"location\": '{\"unformatted\": \"San Francisco, CA\"}',\n",
        "#     \"bse\": \"5a0df436a0884c9aadb1ee068789d101\"\n",
        "# }\n",
        "\n",
        "# # This is the exact same payload from the cURL request\n",
        "# payload = [\n",
        "#     {\n",
        "#         \"operationName\": \"GetBizData\",\n",
        "#         \"variables\": {\n",
        "#             \"FetchPhotosAndCaptions\": False,\n",
        "#             \"BizEncIds\": [\n",
        "#                 \"2rvzTYaiXlqtBe5ZhNDiXA\", \"WHJ2spR-_1P_tbiOqOibjg\", \"QueFVMcMlT-6aZFv2M47mg\",\n",
        "#                 \"BoEUjuDEb6dPiTSIo4XFDw\", \"Ch4EL26AU70Vc-_-fH_fDA\", \"xpzXvAlHO0iBsfhPmYoktg\",\n",
        "#                 \"54FhPcut3uFDbpNCRWUOlQ\", \"6H1OUNCD9NwB-WyaFvJqtA\", \"l_ZnPm9olFZviBRkXVzNFA\",\n",
        "#                 \"AlWyJJ8aH58MSXFujDvhag\", \"f-m7-hyFzkf0HSEeQ2s-9A\", \"8dUaybEPHsZMgr1iKgqgMQ\",\n",
        "#                 \"Fou0GxqJuQUUO0yAmTH1iw\"\n",
        "#             ]\n",
        "#         },\n",
        "#         \"extensions\": {\n",
        "#             \"operationType\": \"query\",\n",
        "#             \"documentId\": \"a727bb910cd9ea97187ae015aef43bfc479b09f354a131e9be04776779785d11\"\n",
        "#         }\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# # Make the request\n",
        "# response = requests.post(url, headers=headers, cookies=cookies, json=payload)\n",
        "\n",
        "# # Check response\n",
        "# if response.status_code == 200:\n",
        "#     data = response.json()\n",
        "#     # Print the relevant part of the response to diagnose the KeyError\n",
        "#     # print(json.dumps(data[0][\"data\"], indent=2))\n",
        "#     businesses = data[0][\"data\"][\"businesses\"]\n",
        "\n",
        "#     for biz in businesses:\n",
        "#         name = biz.get(\"name\")\n",
        "#         rating = biz.get(\"rating\")\n",
        "#         review_count = biz.get(\"reviewCount\")\n",
        "#         print(f\"{name} | Rating: {rating} | Reviews: {review_count}\")\n",
        "# else:\n",
        "#     print(\"Failed:\", response.status_code)\n",
        "#     print(\"Response body:\", response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mlff4ONfDy5",
        "outputId": "fd3cbfd8-997e-4fc3-f702-5e77b935d9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Price                                   Location            City State  \\\n",
            "0   725000                        C42 - Downtown L.A.     Los Angeles    CA   \n",
            "1  1849000  C03 - Sunset Strip - Hollywood Hills West     Los Angeles    CA   \n",
            "2   799000                       676 - Monterey Hills     Los Angeles    CA   \n",
            "3  1000000                                Playa Vista     Playa Vista    CA   \n",
            "4  1150000                             Woodland Hills  Woodland Hills    CA   \n",
            "\n",
            "     Zip   Latitude   Longitude  Beds  Baths    SqFt  Lot Size   MLS Status  \\\n",
            "0  90012  34.047779 -118.235741   1.0    1.0   913.0   14532.0       Active   \n",
            "1  90068  34.127454 -118.351863   3.0    4.0  1904.0    5040.0       Active   \n",
            "2  90042  34.108630 -118.182468   2.0    2.0  1470.0   30243.0       Active   \n",
            "3  90094  33.969619 -118.425058   2.0    2.0  1130.0   61621.0  Coming Soon   \n",
            "4  91367  34.186293 -118.564876   4.0    3.0  1959.0    7315.0       Active   \n",
            "\n",
            "                                                 URL  \n",
            "0  https://www.redfin.com/CA/Los-Angeles/120-S-He...  \n",
            "1  https://www.redfin.com/CA/Los-Angeles/3329-Adi...  \n",
            "2  https://www.redfin.com/CA/Los-Angeles/6221-Mon...  \n",
            "3  https://www.redfin.com/CA/Playa-Vista/7100-Pla...  \n",
            "4  https://www.redfin.com/CA/Woodland-Hills/19808...  \n",
            "Data saved to redfin_listings.csv\n"
          ]
        }
      ],
      "source": [
        "# # Sequential scrapping data from Redfin\n",
        "# import requests\n",
        "# import pandas as pd\n",
        "# import time\n",
        "# import json\n",
        "\n",
        "# headers = {\n",
        "#     \"User-Agent\": \"Mozilla/5.0\"\n",
        "# }\n",
        "\n",
        "# listings = []\n",
        "# max_pages = 100\n",
        "# url = \"https://www.redfin.com/stingray/api/gis\"\n",
        "\n",
        "# for page in range(1, max_pages + 1):\n",
        "#   params = {\n",
        "#       \"al\": 1,\n",
        "#       \"market\": \"LA\",\n",
        "#       \"num_homes\": 100,           # number of listings per page\n",
        "#       \"ord\": \"redfin-recommended-asc\",\n",
        "#       \"page_number\": page,\n",
        "#       \"region_id\": 11203,         # Los Angeles\n",
        "#       \"region_type\": 6,           # city\n",
        "#       \"sf\": \"1,2,5,6,7\",\n",
        "#       \"status\": 9,\n",
        "#       \"uipt\": \"1,2,3,4,5,6\",\n",
        "#       \"v\": 8\n",
        "#   }\n",
        "\n",
        "#   response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "#   if response.status_code != 200:\n",
        "#       print(f\"Failed on page {page}: {response.status_code}\")\n",
        "#       break\n",
        "\n",
        "#   if response.status_code == 200:\n",
        "#       clean_text = response.text\n",
        "#       if clean_text.startswith(\"{}&&\"):\n",
        "#           clean_text = clean_text[4:]\n",
        "#       # print(clean_text)\n",
        "#       data = json.loads(clean_text)\n",
        "#       homes = data.get(\"payload\", {}).get(\"homes\", [])\n",
        "\n",
        "#       if not homes:\n",
        "#           print(f\"No more homes found on page {page}.\")\n",
        "#           break\n",
        "\n",
        "#       for home in homes:\n",
        "#           listings.append({\n",
        "#               \"Price\": home.get(\"price\", {}).get(\"value\"),\n",
        "#               \"Location\": home.get(\"location\",{}).get(\"value\"),\n",
        "#               \"City\": home.get(\"city\"),\n",
        "#               \"State\": home.get(\"state\"),\n",
        "#               \"Zip\": home.get(\"zip\"),\n",
        "#               \"Latitude\": home.get(\"latLong\",{}).get(\"value\",{}).get(\"latitude\"),\n",
        "#               \"Longitude\": home.get(\"latLong\",{}).get(\"value\",{}).get(\"longitude\"),\n",
        "#               \"Beds\": home.get(\"beds\"),\n",
        "#               \"Baths\": home.get(\"baths\"),\n",
        "#               \"SqFt\": home.get(\"sqFt\",{}).get(\"value\"),\n",
        "#               \"Lot Size\": home.get(\"lotSize\",{}).get(\"value\"),\n",
        "#               \"MLS Status\": home.get(\"mlsStatus\"),\n",
        "#               \"URL\": f\"https://www.redfin.com{home.get('url')}\"\n",
        "#           })\n",
        "#   else:\n",
        "#     print(\"Request failed:\", response.status_code)\n",
        "\n",
        "#   # time.sleep(1)\n",
        "# df = pd.DataFrame(listings)\n",
        "# print(df.head())\n",
        "# df.to_csv(\"redfin_listings.csv\", index=False)\n",
        "# print(\"Data saved to redfin_listings.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgLdawuM6OB-",
        "outputId": "d331ea7e-4df6-4e00-89b3-edd1ff6a09e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35000\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# df = pd.read_csv(\"redfin_listings.csv\")\n",
        "# print(df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf11jyDkF0dh",
        "outputId": "6372877b-43ea-4c37-a11c-254cd1c32391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching pages 1 to 500...\n",
            "✅ Batch complete. Total listings so far: 175000\n",
            "Fetching pages 501 to 1000...\n",
            "✅ Batch complete. Total listings so far: 350000\n",
            "Fetching pages 1001 to 1500...\n",
            "✅ Batch complete. Total listings so far: 525000\n",
            "Fetching pages 1501 to 2000...\n",
            "✅ Batch complete. Total listings so far: 700000\n",
            "Fetching pages 2001 to 2500...\n",
            "✅ Batch complete. Total listings so far: 875000\n",
            "Fetching pages 2501 to 3000...\n",
            "✅ Batch complete. Total listings so far: 1050000\n",
            "Fetching pages 3001 to 3500...\n",
            "✅ Batch complete. Total listings so far: 1225000\n",
            "Fetching pages 3501 to 4000...\n",
            "✅ Batch complete. Total listings so far: 1400000\n",
            "Fetching pages 4001 to 4500...\n",
            "✅ Batch complete. Total listings so far: 1575000\n",
            "Fetching pages 4501 to 5000...\n",
            "✅ Batch complete. Total listings so far: 1750000\n",
            "Fetching pages 5001 to 5500...\n",
            "✅ Batch complete. Total listings so far: 1925000\n",
            "Fetching pages 5501 to 6000...\n",
            "✅ Batch complete. Total listings so far: 2100000\n",
            "Fetching pages 6001 to 6500...\n",
            "✅ Batch complete. Total listings so far: 2275000\n",
            "Fetching pages 6501 to 7000...\n",
            "✅ Batch complete. Total listings so far: 2450000\n",
            "Fetching pages 7001 to 7500...\n",
            "✅ Batch complete. Total listings so far: 2625000\n",
            "Fetching pages 7501 to 8000...\n",
            "✅ Batch complete. Total listings so far: 2800000\n",
            "Fetching pages 8001 to 8500...\n",
            "✅ Batch complete. Total listings so far: 2975000\n",
            "Fetching pages 8501 to 9000...\n",
            "✅ Batch complete. Total listings so far: 3150000\n",
            "Fetching pages 9001 to 9500...\n",
            "✅ Batch complete. Total listings so far: 3325000\n",
            "Fetching pages 9501 to 10000...\n",
            "✅ Batch complete. Total listings so far: 3500000\n",
            "\n",
            "🚀 Done! Saved to redfin_async_batched.csv\n"
          ]
        }
      ],
      "source": [
        "# Full Async With Batching + Throttling\n",
        "import asyncio\n",
        "import httpx\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm.asyncio import tqdm_asyncio  # supports async loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "BASE_URL = \"https://www.redfin.com/stingray/api/gis\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "# Static parameters\n",
        "BASE_PARAMS = {\n",
        "    \"al\": 1,\n",
        "    \"market\": \"LA\",\n",
        "    \"num_homes\": 100,\n",
        "    \"ord\": \"redfin-recommended-asc\",\n",
        "    \"region_id\": 11203,\n",
        "    \"region_type\": 6,\n",
        "    \"sf\": \"1,2,5,6,7\",\n",
        "    \"status\": 9,\n",
        "    \"uipt\": \"1,2,3,4,5,6\",\n",
        "    \"v\": 8\n",
        "}\n",
        "\n",
        "# Settings\n",
        "MAX_PAGES = 10000\n",
        "BATCH_SIZE = 500\n",
        "CONCURRENCY = 20\n",
        "SLEEP_BETWEEN_BATCHES = 5\n",
        "\n",
        "semaphore = asyncio.Semaphore(CONCURRENCY)\n",
        "\n",
        "async def fetch_page(client, page_number):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            params = BASE_PARAMS.copy()\n",
        "            params[\"page_number\"] = page_number\n",
        "            response = await client.get(BASE_URL, headers=HEADERS, params=params, timeout=20)\n",
        "            # print(f\"Response text is {response.text}\")\n",
        "            clean_text = response.text[4:]\n",
        "            # print(f\"Clean text is {clean_text}\")\n",
        "            data = json.loads(clean_text)\n",
        "            homes = data.get(\"payload\", {}).get(\"homes\", [])\n",
        "            return homes\n",
        "        except Exception as e:\n",
        "            print(f\"Error on page {page_number}: {e}\")\n",
        "            return []\n",
        "\n",
        "def parse_home(home):\n",
        "    return {\n",
        "        \"Price\": home.get(\"price\", {}).get(\"value\"),\n",
        "        \"Location\": home.get(\"location\",{}).get(\"value\"),\n",
        "        \"City\": home.get(\"city\"),\n",
        "        \"State\": home.get(\"state\"),\n",
        "        \"Zip\": home.get(\"zip\"),\n",
        "        \"Latitude\": home.get(\"latLong\",{}).get(\"value\",{}).get(\"latitude\"),\n",
        "        \"Longitude\": home.get(\"latLong\",{}).get(\"value\",{}).get(\"longitude\"),\n",
        "        \"Beds\": home.get(\"beds\"),\n",
        "        \"Baths\": home.get(\"baths\"),\n",
        "        \"SqFt\": home.get(\"sqFt\",{}).get(\"value\"),\n",
        "        \"Lot Size\": home.get(\"lotSize\",{}).get(\"value\"),\n",
        "        \"MLS Status\": home.get(\"mlsStatus\"),\n",
        "        \"URL\": f\"https://www.redfin.com{home.get('url')}\"\n",
        "    }\n",
        "\n",
        "async def scrape_batch(client, page_range):\n",
        "    tasks = [fetch_page(client, page) for page in page_range]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    # print(f\"results are {results}\")\n",
        "    listings = []\n",
        "    for homes in results:\n",
        "        # print(f\"homes are {homes}\")\n",
        "        for home in homes:\n",
        "            # print(home)\n",
        "            listings.append(parse_home(home))\n",
        "    return listings\n",
        "\n",
        "async def main():\n",
        "    all_listings = []\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        stop_scrapping = False\n",
        "\n",
        "        for batch_start in range(1, MAX_PAGES + 1, BATCH_SIZE):\n",
        "            if stop_scrapping:\n",
        "                break\n",
        "            batch_end = min(batch_start + BATCH_SIZE, MAX_PAGES + 1)\n",
        "            print(f\"Fetching pages {batch_start} to {batch_end - 1}...\")\n",
        "            batch = range(batch_start, batch_end)\n",
        "            listings = await scrape_batch(client, batch)\n",
        "            if not listings:\n",
        "                print(f\"No listings found in batch {batch_start}–{batch_end - 1}. Stopping early.\")\n",
        "                stop_scrapping = True\n",
        "                break\n",
        "            all_listings.extend(listings)\n",
        "            print(f\"✅ Batch complete. Total listings so far: {len(all_listings)}\")\n",
        "            await asyncio.sleep(SLEEP_BETWEEN_BATCHES)\n",
        "\n",
        "        # total_batches = (MAX_PAGES + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "        # for batch_start in tqdm(range(1, MAX_PAGES + 1, BATCH_SIZE), desc=\"Scraping Batches\"):\n",
        "        #     batch_end = min(batch_start + BATCH_SIZE, MAX_PAGES + 1)\n",
        "        #     batch = range(batch_start, batch_end)\n",
        "        #     listings = await scrape_batch(client, batch)\n",
        "        #     all_listings.extend(listings)\n",
        "        #     await asyncio.sleep(SLEEP_BETWEEN_BATCHES)\n",
        "    return pd.DataFrame(all_listings)\n",
        "\n",
        "# For notebook environments:\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "df = await main()\n",
        "df.to_csv(\"redfin_async_batched.csv\", index=False)\n",
        "print(\"\\n🚀 Done! Saved to redfin_async_batched.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning and Preparing Data"
      ],
      "metadata": {
        "id": "qvdht4Tq9gS-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKWut673n/ZaTcKSiIl0C9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}